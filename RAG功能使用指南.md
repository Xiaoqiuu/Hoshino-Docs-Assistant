# RAG 文档问答功能使用指南

## 快速开始

### 1. 首次使用前的准备

RAG 功能需要下载嵌入模型（约 80MB）。如果你在中国大陆，建议先配置镜像源：

**方法 1：使用配置脚本（推荐）**
```bash
双击运行 "配置镜像源.bat"
```

**方法 2：手动配置**
1. 复制 `.env.example` 为 `.env`
2. 在 `.env` 文件中添加：
```env
HUGGINGFACE_MIRROR=https://hf-mirror.com
```

### 2. 启动应用

```bash
双击运行 "双击我运行.bat"
```

### 3. 上传文档

1. 点击左侧导航栏的"文档库"图标
2. 点击"上传文档"按钮
3. 选择要上传的文档（支持 PDF、TXT、MD、DOCX 等格式）
4. 等待文档处理完成

**首次上传时**：
- 系统会自动下载嵌入模型（约 80MB）
- 下载时间取决于网络速度（通常 1-5 分钟）
- 系统会显示下载进度
- 如果下载失败，会自动重试（最多 3 次）

### 4. 使用文档问答

1. 在聊天界面输入问题
2. 系统会自动从文档库中检索相关内容
3. AI 会基于检索到的内容回答问题

## 常见问题

### Q1: 模型下载失败怎么办？

**错误信息**：
```
嵌入模型加载失败: TypeError: fetch failed
Error: read ECONNRESET
```

**解决方案**：

1. **配置镜像源**（推荐）
   - 运行 `配置镜像源.bat`
   - 选择 hf-mirror.com
   - 重启应用

2. **配置代理**
   - 在 `.env` 文件中添加：
   ```env
   HTTP_PROXY=http://127.0.0.1:7890
   HTTPS_PROXY=http://127.0.0.1:7890
   ```
   - 将端口改为你的代理端口
   - 重启应用

3. **等待自动重试**
   - 系统会自动重试 3 次
   - 每次重试间隔递增（2秒、4秒、6秒）

4. **手动下载模型**
   - 查看 `模型下载问题解决方案.md` 获取详细步骤

### Q2: 支持哪些文档格式？

- PDF (.pdf)
- 文本文件 (.txt)
- Markdown (.md)
- Word 文档 (.docx)
- 更多格式持续添加中...

### Q3: 文档大小有限制吗？

- 单个文档建议不超过 10MB
- 文档会被自动分块处理
- 每个分块约 500-1000 字符

### Q4: 可以上传多少个文档？

- 没有数量限制
- 所有文档存储在本地数据库
- 建议定期清理不需要的文档

### Q5: 如何删除文档？

1. 打开文档库
2. 找到要删除的文档
3. 点击删除按钮
4. 确认删除

### Q6: 文档数据存储在哪里？

- 文档内容：`./data/documents.db`
- 向量索引：`./data/vectors.db`
- 模型缓存：`./.cache/models/`

### Q7: 如何提高检索准确度？

1. **上传高质量文档**
   - 文档内容清晰、结构化
   - 避免扫描件或图片文字

2. **使用精确的问题**
   - 问题要具体明确
   - 包含关键词

3. **合理组织文档**
   - 相关内容放在同一文档
   - 避免重复内容

### Q8: RAG 和普通对话有什么区别？

| 特性 | 普通对话 | RAG 对话 |
|------|---------|---------|
| 知识来源 | AI 训练数据 | 你上传的文档 |
| 准确性 | 可能过时或不准确 | 基于你的文档，更准确 |
| 可追溯性 | 无法追溯来源 | 显示引用来源 |
| 适用场景 | 通用问题 | 专业领域、私有知识 |

## 性能优化建议

### 文档上传优化

1. **批量上传**
   - 一次上传多个文档更高效
   - 系统会并行处理

2. **文档预处理**
   - 移除不必要的格式
   - 提取纯文本内容

3. **合理分类**
   - 按主题组织文档
   - 便于后续管理

### 检索优化

1. **使用关键词**
   - 在问题中包含文档中的关键词
   - 提高检索准确度

2. **上下文提示**
   - 告诉 AI 在哪个文档中查找
   - 例如："根据用户手册，如何..."

3. **迭代提问**
   - 如果第一次回答不满意
   - 换个方式重新提问

## 技术细节

### 嵌入模型

- 模型：Xenova/all-MiniLM-L6-v2
- 向量维度：384
- 最大输入：512 tokens
- 模型大小：约 80MB

### 向量检索

- 相似度算法：余弦相似度
- 检索数量：Top 5
- 最小相似度：0.3

### 文档处理

- 分块大小：500-1000 字符
- 分块重叠：100 字符
- 支持格式：PDF、TXT、MD、DOCX

## 故障排除

### 问题：应用启动后立即崩溃

**可能原因**：
- Node.js 版本不兼容
- 依赖未正确安装

**解决方案**：
```bash
# 重新安装依赖
npm install

# 重新构建
npm run build

# 启动应用
npm start
```

### 问题：文档上传后无法检索

**可能原因**：
- 文档处理失败
- 向量化失败

**解决方案**：
1. 查看控制台日志
2. 检查文档格式是否支持
3. 尝试重新上传

### 问题：检索结果不相关

**可能原因**：
- 问题表述不清
- 文档内容不匹配

**解决方案**：
1. 使用更具体的问题
2. 检查文档内容是否包含相关信息
3. 尝试不同的关键词

## 更新日志

### v1.0.0 (当前版本)

- ✅ 基础 RAG 功能
- ✅ 文档上传和管理
- ✅ 向量检索
- ✅ 多格式支持
- ✅ 自动重试机制
- ✅ 镜像源支持

### 计划中的功能

- 🔄 更多文档格式支持
- 🔄 文档预览功能
- 🔄 高级检索选项
- 🔄 文档标签和分类
- 🔄 检索结果高亮

## 需要帮助？

如果遇到问题：

1. 查看 `模型下载问题解决方案.md`
2. 查看控制台日志
3. 检查 `.env` 配置
4. 提交 Issue 到 GitHub

## 相关文档

- [模型下载问题解决方案](./模型下载问题解决方案.md)
- [开发文档](./DEVELOPMENT.md)
- [项目概述](./PROJECT_OVERVIEW.md)
