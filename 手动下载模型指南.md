# 手动下载模型指南

## 目录结构

模型文件应该放在项目根目录下的以下位置：

```
你的项目根目录/
├── .cache/                          ← 创建这个文件夹
│   └── models/                      ← 创建这个文件夹
│       └── Xenova/                  ← 创建这个文件夹
│           └── all-MiniLM-L6-v2/    ← 创建这个文件夹
│               ├── config.json
│               ├── tokenizer.json
│               ├── tokenizer_config.json
│               └── onnx/            ← 创建这个文件夹
│                   ├── model.onnx
│                   └── model_quantized.onnx
```

## 完整路径示例

假设你的项目在 `C:\Users\xiaoqiuu\Documents\workspace-front\Hoshino-Document-LightProject`

那么模型文件应该放在：

```
C:\Users\xiaoqiuu\Documents\workspace-front\Hoshino-Document-LightProject\.cache\models\Xenova\all-MiniLM-L6-v2\
```

## 详细步骤

### 第 1 步：创建目录结构

在项目根目录下运行以下命令：

```cmd
mkdir .cache
mkdir .cache\models
mkdir .cache\models\Xenova
mkdir .cache\models\Xenova\all-MiniLM-L6-v2
mkdir .cache\models\Xenova\all-MiniLM-L6-v2\onnx
```

或者使用 PowerShell：

```powershell
New-Item -ItemType Directory -Path ".cache\models\Xenova\all-MiniLM-L6-v2\onnx" -Force
```

### 第 2 步：下载模型文件

访问以下网址下载文件：

**镜像源（推荐）**：
https://hf-mirror.com/Xenova/all-MiniLM-L6-v2/tree/main

**官方源**：
https://huggingface.co/Xenova/all-MiniLM-L6-v2/tree/main

需要下载的文件：

1. **根目录文件**（放在 `all-MiniLM-L6-v2` 文件夹）：
   - `config.json` (约 612 字节)
   - `tokenizer.json` (约 466 KB)
   - `tokenizer_config.json` (约 366 字节)

2. **onnx 目录文件**（放在 `all-MiniLM-L6-v2\onnx` 文件夹）：
   - `model.onnx` (约 90 MB)
   - `model_quantized.onnx` (约 23 MB)

### 第 3 步：放置文件

将下载的文件按照以下方式放置：

```
.cache\models\Xenova\all-MiniLM-L6-v2\
├── config.json                    ← 放这里
├── tokenizer.json                 ← 放这里
├── tokenizer_config.json          ← 放这里
└── onnx\
    ├── model.onnx                 ← 放这里
    └── model_quantized.onnx       ← 放这里
```

### 第 4 步：验证文件

运行以下命令验证文件是否正确放置：

```cmd
dir .cache\models\Xenova\all-MiniLM-L6-v2
dir .cache\models\Xenova\all-MiniLM-L6-v2\onnx
```

你应该看到：

```
.cache\models\Xenova\all-MiniLM-L6-v2 的目录

2024/11/25  10:00               612 config.json
2024/11/25  10:00           466,000 tokenizer.json
2024/11/25  10:00               366 tokenizer_config.json
2024/11/25  10:00        <DIR>      onnx

.cache\models\Xenova\all-MiniLM-L6-v2\onnx 的目录

2024/11/25  10:00        90,000,000 model.onnx
2024/11/25  10:00        23,000,000 model_quantized.onnx
```

### 第 5 步：重启应用

1. 关闭应用（如果正在运行）
2. 双击运行 "双击我运行.bat"
3. 尝试上传文档

## 快速命令（一键创建目录）

将以下内容保存为 `创建模型目录.bat`，然后双击运行：

```batch
@echo off
chcp 65001 >nul
echo 正在创建模型目录结构...
mkdir .cache\models\Xenova\all-MiniLM-L6-v2\onnx 2>nul
echo.
echo 目录创建完成！
echo.
echo 请将下载的文件放到以下位置：
echo.
echo 根目录文件放到：
echo %CD%\.cache\models\Xenova\all-MiniLM-L6-v2\
echo.
echo onnx 文件放到：
echo %CD%\.cache\models\Xenova\all-MiniLM-L6-v2\onnx\
echo.
pause
```

## 下载链接（镜像源）

直接下载链接（使用 hf-mirror.com）：

1. config.json
   https://hf-mirror.com/Xenova/all-MiniLM-L6-v2/resolve/main/config.json

2. tokenizer.json
   https://hf-mirror.com/Xenova/all-MiniLM-L6-v2/resolve/main/tokenizer.json

3. tokenizer_config.json
   https://hf-mirror.com/Xenova/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json

4. model.onnx
   https://hf-mirror.com/Xenova/all-MiniLM-L6-v2/resolve/main/onnx/model.onnx

5. model_quantized.onnx
   https://hf-mirror.com/Xenova/all-MiniLM-L6-v2/resolve/main/onnx/model_quantized.onnx

## 使用下载工具

如果浏览器下载不稳定，可以使用以下工具：

### 方法 1：使用 curl（Windows 10+）

```cmd
cd .cache\models\Xenova\all-MiniLM-L6-v2

curl -L -o config.json https://hf-mirror.com/Xenova/all-MiniLM-L6-v2/resolve/main/config.json
curl -L -o tokenizer.json https://hf-mirror.com/Xenova/all-MiniLM-L6-v2/resolve/main/tokenizer.json
curl -L -o tokenizer_config.json https://hf-mirror.com/Xenova/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json

cd onnx
curl -L -o model.onnx https://hf-mirror.com/Xenova/all-MiniLM-L6-v2/resolve/main/onnx/model.onnx
curl -L -o model_quantized.onnx https://hf-mirror.com/Xenova/all-MiniLM-L6-v2/resolve/main/onnx/model_quantized.onnx
```

### 方法 2：使用 PowerShell

```powershell
$baseUrl = "https://hf-mirror.com/Xenova/all-MiniLM-L6-v2/resolve/main"
$basePath = ".cache\models\Xenova\all-MiniLM-L6-v2"

# 创建目录
New-Item -ItemType Directory -Path "$basePath\onnx" -Force

# 下载文件
Invoke-WebRequest -Uri "$baseUrl/config.json" -OutFile "$basePath\config.json"
Invoke-WebRequest -Uri "$baseUrl/tokenizer.json" -OutFile "$basePath\tokenizer.json"
Invoke-WebRequest -Uri "$baseUrl/tokenizer_config.json" -OutFile "$basePath\tokenizer_config.json"
Invoke-WebRequest -Uri "$baseUrl/onnx/model.onnx" -OutFile "$basePath\onnx\model.onnx"
Invoke-WebRequest -Uri "$baseUrl/onnx/model_quantized.onnx" -OutFile "$basePath\onnx\model_quantized.onnx"
```

## 常见问题

### Q: 我只下载了部分文件，可以吗？

A: 不可以，必须下载所有 5 个文件，缺少任何一个都会导致加载失败。

### Q: 文件大小不对怎么办？

A: 重新下载该文件，确保下载完整。参考大小：
- config.json: ~612 字节
- tokenizer.json: ~466 KB
- tokenizer_config.json: ~366 字节
- model.onnx: ~90 MB
- model_quantized.onnx: ~23 MB

### Q: 放错位置了怎么办？

A: 删除 `.cache` 文件夹，重新按照步骤创建目录和放置文件。

### Q: 下载后还是报错？

A: 检查：
1. 文件是否完整（大小是否正确）
2. 目录结构是否正确
3. 文件名是否正确（区分大小写）
4. 重启应用

### Q: 可以使用其他版本的模型吗？

A: 目前代码中硬编码了 `Xenova/all-MiniLM-L6-v2`，如需使用其他模型需要修改代码。

## 验证脚本

创建 `验证模型文件.bat` 并运行：

```batch
@echo off
chcp 65001 >nul
echo 正在验证模型文件...
echo.

set MODEL_PATH=.cache\models\Xenova\all-MiniLM-L6-v2

if not exist "%MODEL_PATH%" (
    echo ✗ 模型目录不存在
    goto :end
)

echo ✓ 模型目录存在
echo.

if exist "%MODEL_PATH%\config.json" (
    echo ✓ config.json 存在
) else (
    echo ✗ config.json 不存在
)

if exist "%MODEL_PATH%\tokenizer.json" (
    echo ✓ tokenizer.json 存在
) else (
    echo ✗ tokenizer.json 不存在
)

if exist "%MODEL_PATH%\tokenizer_config.json" (
    echo ✓ tokenizer_config.json 存在
) else (
    echo ✗ tokenizer_config.json 不存在
)

if exist "%MODEL_PATH%\onnx\model.onnx" (
    echo ✓ model.onnx 存在
) else (
    echo ✗ model.onnx 不存在
)

if exist "%MODEL_PATH%\onnx\model_quantized.onnx" (
    echo ✓ model_quantized.onnx 存在
) else (
    echo ✗ model_quantized.onnx 不存在
)

echo.
echo 验证完成！

:end
pause
```

## 总结

**关键路径**：
```
项目根目录\.cache\models\Xenova\all-MiniLM-L6-v2\
```

**必需文件**：
- config.json
- tokenizer.json
- tokenizer_config.json
- onnx/model.onnx
- onnx/model_quantized.onnx

**下载源**：
- 推荐：https://hf-mirror.com/Xenova/all-MiniLM-L6-v2
- 备用：https://huggingface.co/Xenova/all-MiniLM-L6-v2

完成后重启应用即可使用！
