# 测试流式输出和思维链功能

## 快速测试步骤

### 测试 1：流式输出

1. **启动应用**
   ```bash
   npm run dev
   ```

2. **配置设置**
   - 点击右上角 ⚙️ 设置
   - 确保"启用流式输出"已勾选
   - 点击"保存"

3. **发送测试消息**
   ```
   请写一首关于春天的诗
   ```

4. **预期结果**
   - 回复内容逐字显示（打字机效果）
   - 不是一次性全部显示

### 测试 2：思维链显示（云端模型）

1. **配置推理模型**
   - 打开设置
   - 选择云端模型：`deepseek-reasoner`
   - 勾选"显示思维链内容"
   - 输入有效的 API Key
   - 点击"保存"

2. **发送推理问题**
   ```
   9.11 和 9.8 哪个更大？请详细解释。
   ```

3. **预期结果**
   - 回复上方显示 "🧠 思维过程 ▶"
   - 点击可展开查看 AI 的思考过程
   - 下方显示最终答案

### 测试 3：思维链显示（本地模型）

1. **确保 Ollama 已安装并运行**
   ```bash
   ollama serve
   ```

2. **下载推理模型**
   ```bash
   ollama pull deepseek-r1:7b
   ```

3. **配置本地模型**
   - 打开设置
   - 勾选"使用本地模型（Ollama）"
   - 本地模型输入：`deepseek-r1:7b`
   - 勾选"显示思维链内容"
   - 点击"保存"

4. **发送推理问题**
   ```
   How many Rs are there in the word 'strawberry'?
   ```

5. **预期结果**
   - 显示思维链面板
   - 可以看到模型的推理过程
   - 最终给出正确答案

### 测试 4：关闭流式输出

1. **修改设置**
   - 打开设置
   - 取消勾选"启用流式输出"
   - 点击"保存"

2. **发送消息**
   ```
   介绍一下人工智能
   ```

3. **预期结果**
   - 回复内容一次性全部显示
   - 没有打字机效果

### 测试 5：关闭思维链显示

1. **修改设置**
   - 打开设置
   - 取消勾选"显示思维链内容"
   - 点击"保存"

2. **发送推理问题**
   ```
   计算 123 × 456 的结果
   ```

3. **预期结果**
   - 不显示思维链面板
   - 只显示最终答案

## 推荐测试问题

### 适合测试思维链的问题

1. **数学推理**
   ```
   9.11 和 9.8 哪个更大？
   ```

2. **逻辑推理**
   ```
   如果所有的猫都怕水，而 Tom 是一只猫，那么 Tom 怕水吗？
   ```

3. **字符计数**
   ```
   单词 'strawberry' 中有多少个字母 'r'？
   ```

4. **复杂计算**
   ```
   一个长方形的长是 12.5 米，宽是 8.3 米，求面积和周长。
   ```

5. **推理题**
   ```
   三个人 A、B、C，其中一个说真话，两个说假话。
   A 说：B 说假话
   B 说：C 说假话
   C 说：A 和 B 都说假话
   谁说的是真话？
   ```

### 适合测试流式输出的问题

1. **长文本生成**
   ```
   写一篇 500 字的文章，介绍人工智能的发展历史
   ```

2. **代码生成**
   ```
   用 Python 写一个快速排序算法，并添加详细注释
   ```

3. **故事创作**
   ```
   写一个关于机器人和人类成为朋友的短篇故事
   ```

## 检查点

### ✅ 流式输出检查

- [ ] 文字逐字显示
- [ ] 显示速度流畅
- [ ] 可以正常完成
- [ ] 错误时有提示
- [ ] 可以开关功能

### ✅ 思维链检查

- [ ] 思维链面板显示
- [ ] 可以折叠/展开
- [ ] 内容格式正确
- [ ] 支持 Markdown
- [ ] 可以滚动查看
- [ ] 可以开关功能

### ✅ 兼容性检查

- [ ] 云端模型正常工作
- [ ] 本地模型正常工作
- [ ] 普通模式正常工作
- [ ] RAG 模式正常工作
- [ ] 设置保存正确

## 常见问题

### Q1: 流式输出很慢或卡顿

**A:** 这可能是网络问题或 API 响应慢。可以：
- 检查网络连接
- 尝试使用本地模型
- 关闭流式输出使用普通模式

### Q2: 思维链内容是空的

**A:** 可能原因：
- 使用的不是推理模型
- 问题太简单，不需要推理
- API 配置问题

### Q3: 设置保存后不生效

**A:** 尝试：
- 重启应用
- 清除缓存
- 检查配置文件

## 调试技巧

### 1. 查看控制台日志

打开开发者工具（F12），查看：
- 主进程日志
- 渲染进程日志
- 网络请求

### 2. 检查配置文件

配置文件位置：
```
Windows: %APPDATA%/hoshino/config.json
macOS: ~/Library/Application Support/hoshino/config.json
Linux: ~/.config/hoshino/config.json
```

### 3. 测试 API 连接

在设置中点击"测试连接"按钮，确认：
- API Key 有效
- 网络连接正常
- 模型可用

### 4. 查看 IPC 通信

在控制台中监听事件：
```javascript
// 在渲染进程控制台中
window.electronAPI.onMessageStreamChunk((data) => {
  console.log('Stream chunk:', data);
});
```

## 性能测试

### 测试流式输出性能

1. 发送长文本生成请求
2. 观察：
   - 首字延迟（TTFB）
   - 字符显示速度
   - CPU 使用率
   - 内存使用

### 测试思维链性能

1. 发送复杂推理问题
2. 观察：
   - 思维链长度
   - 渲染性能
   - 内存占用

## 报告问题

如果发现问题，请提供：

1. **环境信息**
   - 操作系统
   - Node.js 版本
   - Electron 版本

2. **配置信息**
   - 使用的模型
   - 是否启用流式输出
   - 是否启用思维链

3. **重现步骤**
   - 具体操作步骤
   - 发送的消息内容
   - 预期结果 vs 实际结果

4. **日志信息**
   - 控制台错误
   - 网络请求
   - 配置文件内容

## 下一步

测试完成后，可以：

1. 根据个人喜好调整设置
2. 尝试不同的模型
3. 探索更多功能
4. 提供反馈和建议
