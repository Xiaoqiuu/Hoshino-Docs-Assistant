Hoshino 文档助手使用说明

=== 快速开始 ===

1. 双击"双击我运行.bat"启动程序
2. 程序会在系统托盘显示 Hoshino 图标
3. 按 Ctrl+Alt+H 唤出助手窗口
4. 点击右上角 ⚙️ 进入设置

=== 两种使用方式 ===

【方式一：云端模型（需要 API Key）】
1. 访问 https://platform.deepseek.com 注册并获取 API Key
2. 在设置中输入 API Key
3. 点击"测试连接"确认配置
4. 保存设置即可使用

【方式二：本地模型（推荐，完全免费）】
1. 下载安装 Ollama：https://ollama.com
2. 打开命令行，运行：ollama serve
3. 下载模型：ollama pull deepseek-r1:7b
4. 在设置中勾选"使用本地模型（Ollama）"
5. 点击"测试连接"确认配置
6. 保存设置即可使用

=== 对话模式 ===

- 普通聊天：直接输入问题，AI 会回答
- 文档模式：选中任意文本后按 Ctrl+Alt+H，AI 会基于文本内容回答
- 图片识别：在输入框按 Ctrl+V 粘贴截图，自动识别图片中的文字

=== 快捷键 ===

- Ctrl+Alt+H: 唤出/隐藏窗口
- ESC: 隐藏窗口
- 托盘图标单击：唤出窗口
- 托盘图标右键：查看菜单选项

=== 推荐模型 ===

本地模型（通过 Ollama）：
- deepseek-r1:7b - 最佳平衡，推荐大多数用户（需要 8GB 内存）
- deepseek-r1:14b - 更强大，需要 16GB 内存
- qwen2.5:7b - 中文表现优秀（需要 8GB 内存）
- llama3.2:3b - 轻量级，速度快（需要 4GB 内存）

云端模型（通过 API）：
- deepseek-chat - 标准模型
- deepseek-reasoner - 推理模型

=== 常见问题 ===

Q: 本地模型提示"无法连接到 Ollama 服务"？
A: 确保运行了 ollama serve 命令

Q: 本地模型提示"请求失败"？
A: 确保已下载模型：ollama pull deepseek-r1:7b

Q: 响应速度慢？
A: 使用更小的模型（如 3B 或 7B）

Q: 内存不足？
A: 7B 模型需要约 8GB 内存，可以使用 3B 模型

Q: 如何查看已安装的模型？
A: 运行命令：ollama list

Q: OCR 识别不准确？
A: 确保截图清晰，文字可读，印刷体识别效果最好

Q: OCR 识别速度慢？
A: 首次使用需要下载语言包，后续会快很多

=== 更多信息 ===

详细文档：README.md
本地模型指南：OLLAMA_LOCAL_MODEL.md
