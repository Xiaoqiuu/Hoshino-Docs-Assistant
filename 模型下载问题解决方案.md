# 嵌入模型下载问题解决方案

## 问题描述

在首次使用文档 RAG 功能时，系统需要从 Hugging Face 下载嵌入模型（约 80MB）。如果遇到网络连接问题，可能会出现以下错误：

```
嵌入模型加载失败: TypeError: fetch failed
Error: read ECONNRESET
```

## 解决方案

### 方案 1：使用 Hugging Face 镜像源（推荐）

**适用于中国大陆用户**

1. 在项目根目录创建 `.env` 文件（如果还没有）
2. 添加以下配置：

```env
HUGGINGFACE_MIRROR=https://hf-mirror.com
```

3. 重启应用

### 方案 2：配置代理

如果你有可用的代理服务器：

1. 在 `.env` 文件中添加：

```env
HTTP_PROXY=http://127.0.0.1:7890
HTTPS_PROXY=http://127.0.0.1:7890
```

（将端口号改为你的代理端口）

2. 重启应用

### 方案 3：手动下载模型

1. 访问模型页面：https://huggingface.co/Xenova/all-MiniLM-L6-v2
   - 或使用镜像：https://hf-mirror.com/Xenova/all-MiniLM-L6-v2

2. 下载以下文件到 `.cache/models/Xenova/all-MiniLM-L6-v2/` 目录：
   - `config.json`
   - `tokenizer.json`
   - `tokenizer_config.json`
   - `onnx/model.onnx`
   - `onnx/model_quantized.onnx`

3. 重启应用

### 方案 4：多次重试

系统已内置自动重试机制（最多 3 次）。如果网络不稳定，可以：

1. 等待系统自动重试完成
2. 如果失败，关闭应用后重新打开
3. 再次尝试上传文档

## 验证模型是否下载成功

模型下载成功后，会在 `.cache` 目录下看到以下结构：

```
.cache/
└── models/
    └── Xenova/
        └── all-MiniLM-L6-v2/
            ├── config.json
            ├── tokenizer.json
            ├── tokenizer_config.json
            └── onnx/
                ├── model.onnx
                └── model_quantized.onnx
```

## 常见问题

### Q: 为什么需要下载模型？
A: 嵌入模型用于将文档内容转换为向量，实现智能语义搜索。这是 RAG（检索增强生成）功能的核心组件。

### Q: 模型只需要下载一次吗？
A: 是的，模型下载后会缓存在本地，之后使用不需要重新下载。

### Q: 可以使用其他模型吗？
A: 目前系统使用 `Xenova/all-MiniLM-L6-v2`，这是一个轻量级且效果良好的模型。如需更换模型，需要修改代码。

### Q: 下载速度很慢怎么办？
A: 建议使用镜像源（方案 1）或配置代理（方案 2）。

## 技术细节

- 模型大小：约 80MB
- 向量维度：384
- 最大输入长度：512 tokens
- 下载超时时间：2 分钟
- 自动重试次数：3 次
- 重试间隔：递增（2秒、4秒、6秒）

## 需要帮助？

如果以上方案都无法解决问题，请检查：

1. 网络连接是否正常
2. 防火墙是否阻止了应用的网络访问
3. 是否有足够的磁盘空间（至少 200MB）
4. 查看控制台日志获取更详细的错误信息
