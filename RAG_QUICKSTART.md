# RAG 系统快速开始指南 🚀

## 什么是 RAG？

RAG（Retrieval-Augmented Generation，检索增强生成）是一种结合了文档检索和 AI 生成的技术。它可以让 AI 基于你上传的文档内容来回答问题，而不是仅凭训练数据。

## 快速开始

### 第一步：打开文档库

1. 启动 Hoshino 应用（快捷键：`Ctrl+Alt+H`）
2. 点击底部导航栏的 **📚 文档** 图标
3. 文档库界面会弹出

### 第二步：上传 PDF 文档

1. 点击 **📄 上传 PDF** 按钮
2. 选择你要上传的 PDF 文件
3. 等待处理完成（会显示进度）

**处理过程包括：**
- 解析 PDF 文本
- 智能分块
- 向量化（首次使用需要下载模型，约 80MB）
- 保存到本地

**预计时间：**
- 小文档（< 10 页）：30-60 秒
- 中等文档（10-50 页）：1-3 分钟
- 大文档（> 50 页）：3-10 分钟

### 第三步：向文档提问

1. 在文档列表中**勾选**你想要查询的文档（可多选）
2. 在底部输入框输入你的问题
3. 点击 **提问** 按钮
4. AI 会基于文档内容回答你的问题

**示例问题：**
- "这份文档的主要内容是什么？"
- "文档中提到的关键技术有哪些？"
- "第 5 页讲了什么？"
- "文档中关于 XXX 的部分在哪里？"

### 第四步：查看答案和来源

AI 的回答会显示在聊天界面中，包括：
- **答案内容**：基于文档的回答
- **来源引用**：显示信息来自哪个文档的哪一页

## 功能说明

### 文档管理

**上传文档**
- 支持格式：PDF
- 文件大小：建议 < 50MB
- 自动索引：上传后自动处理

**查看文档**
- 文档名称
- 页数和文档块数
- 文件大小
- 上传时间
- 处理状态

**删除文档**
- 点击文档右侧的 🗑️ 按钮
- 确认删除
- 会同时删除文档文件和向量数据

### 多文档问答

你可以同时选择多个文档进行问答：
1. 勾选多个文档
2. 输入问题
3. AI 会在所有选中的文档中检索相关内容

**适用场景：**
- 对比多份文档
- 跨文档查找信息
- 综合多个来源的信息

### 统计信息

文档库顶部显示：
- **文档总数**：已上传的文档数量
- **就绪**：已完成索引的文档
- **处理中**：正在索引的文档
- **文档块**：总共的文本块数量

## 使用技巧

### 提问技巧

**✅ 好的问题：**
- "文档中提到的主要观点是什么？"
- "关于 XXX 的具体步骤是什么？"
- "文档中有哪些数据支持 YYY？"
- "第 N 页的内容总结一下"

**❌ 不好的问题：**
- "你好"（太宽泛）
- "是吗？"（缺少上下文）
- 超出文档范围的问题

### 文档准备

**最佳实践：**
- 使用文本 PDF（非扫描件）
- 文档结构清晰
- 避免过多图片和表格
- 文件大小适中

**暂不支持：**
- 扫描件 PDF（需要 OCR）
- 图片中的文字
- 表格数据提取
- DOCX、TXT 等其他格式

### 性能优化

**加快索引速度：**
- 首次使用会下载模型（仅一次）
- 小文档优先测试
- 避免同时上传多个大文档

**节省存储空间：**
- 定期删除不需要的文档
- 避免重复上传相同文档

## 常见问题

### Q: 首次使用很慢？
A: 首次使用需要下载嵌入模型（约 80MB），之后会快很多。

### Q: 支持哪些文档格式？
A: 目前仅支持 PDF 格式，且必须是文本 PDF（非扫描件）。

### Q: 可以上传多大的文档？
A: 建议单个文档 < 50MB，页数 < 100 页。

### Q: 答案不准确怎么办？
A: 尝试：
- 更具体的问题
- 选择相关的文档
- 检查文档内容是否清晰

### Q: 文档数据存在哪里？
A: 存储在应用的用户数据目录：
- Windows: `%APPDATA%/hoshino-doc-assistant/`
- macOS: `~/Library/Application Support/hoshino-doc-assistant/`
- Linux: `~/.config/hoshino-doc-assistant/`

### Q: 如何删除所有数据？
A: 删除上述用户数据目录即可。

### Q: 支持离线使用吗？
A: 模型下载后可以离线使用，但需要 AI 服务（本地 Ollama 或云端 API）。

## 技术细节

### 工作原理

1. **文档解析**：提取 PDF 文本内容
2. **文本分块**：将长文本分成 800 字符的块（100 字符重叠）
3. **向量化**：使用 all-MiniLM-L6-v2 模型生成 384 维向量
4. **存储**：保存向量到本地 JSON 文件
5. **检索**：计算问题和文档块的余弦相似度
6. **生成**：将最相关的 5 个文档块作为上下文发送给 AI

### 模型信息

- **嵌入模型**：Xenova/all-MiniLM-L6-v2
- **模型大小**：~80MB
- **向量维度**：384
- **支持语言**：多语言（包括中文）

### 数据隐私

- 所有数据存储在本地
- 不会上传到云端（除非使用云端 AI 服务）
- 可以随时删除数据

## 下一步

### 进阶使用
- 尝试多文档联合问答
- 探索不同类型的问题
- 结合其他功能（OCR、本地模型）

### 反馈和建议
如果遇到问题或有改进建议，欢迎反馈！

---

**祝你使用愉快！** 🎉
